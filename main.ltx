%&main_preamble
\endofdump
\begin{document}

\maketitle

\begin{abstract}
    \noindent
     \laurie{Maybe something like ``The yk system uses meta-tracing to turn
     existing C interpreters into JIT compilers. However, not all compiler
     optimisations are safe to use with yk specifically, or meta-tracing in
     general. yk pessimistically turns off all optimisations, slowing down the
     normal interpreter considerably. I am investigating regaining as much of
     the last performance as possible. This report shows progress to date and
     plans for the future.''}
     JIT compilation gives dynamic languages speed of compiled code with
     flexibility of interpretation. One variant of  which is tracing JIT, in
     which the VM identifies the frequently executed, ‘hot’ program paths at
     runtime, records the instructions in a trace and uses the trace instead of
     original code for hot paths. However, they are quite hard to implement. In
     Meta-tracing, language interpreters are built on top of a common tracing
     JIT compiler, removing the need to re-implement tracing JIT for every
     language. This separates language implementation concerns from JIT
     compilation. However, retrofitting meta-tracing system such as yk into
     existing C-interpreters brings challenges to their performance. The aim of
     my PhD is find ways to speed up retrofitting meta-tracing system (i.e~yk)
     into existing interpreters, In this report, I first find optimisation pass
     sequence (from tradition passes such as O2) using recursive and stochastic
     method, the end result, when JIT is turned of is performance improvement by
     1.5-2 times for yklua, a C-based interpreter which uses yk. Next, I dig
     deeper into reasons for runtime performance overhead introduce by yk in
     C-based interpreters. 

    \laurie{i think you need to try writing the abstract now, because it will
    guide you for the rest of the report. The advice in point 4 of
    https://plg.uwaterloo.ca/~migod/research/beckOOPSLA.html is an excellent
    starting point.}
\end{abstract}

\section{Introduction}

\laurie{this isn't exactly an introduction yet: it's some background, then a
solution. i would start by writing the abstract to help you crystalise what
you're trying to do. then you'll find it much easier to edit the introduction
into the right sort of shape.}

Modern compilers have huge number of optimisation passes available. These
optimisation passes target unique segments of program, such as transforming
a function, basic block or whole program. Further, these optimisations can be
applied at different stages of compilation pipelines. The sequence of passes
try to retain the semantic of the program while potentially improving program's
performance. There are are two type of passes: Analysis and Transformation.
Both of these passes work together, the analysis passes collect information about 
the program and transformation passes are responsible for using the collected 
information and change the program. 
Example of optimisation level provided by modern compilers are: O0, O1, O2,
O3, and Og. The two major compilers gcc and clang have 200 and 100+
optimisation passes respectively, their sequence is called as optimisation
sequence. By default without optimisations level all of the passes are turned 
off, and an expert can choose to turn on and off passes accordingly.\iti{add reference}

Since some optimisation passes depends on others to enable program's
transformation, choosing a right sequence (and order of passes) is important for
program's performance either in respect to execution time or code size. This is
known as phase ordering problem. \laurie{whoah, this is a big jump! you've gone from generic background straight into your solution, without ever defining what problem you're trying to solve} Genetic algorithm is used to solve this problem
in this report, since the number of passes are a lot (around 90) this makes the
our search space huge (i.e~if we try all sequence irrespective of ordering we
would have to try $2^{90} - 1$ possible combinations!).
Using genetic algorithm helps us to find an optimal pass sequence for our
oracle\footnote{The oracle is the test and benchmark suite of our choice.
}. 
Genetic algorithm is well-known stochastic algorithm which is adopted on
the basis of theory of evolution. This algorithm has been used by several
researchers to solve phase-ordering problemi\iti{add citation}.

This report focuses on solving phase-ordering problem using genetic algorithm
for yk and yklua \laurie{yk and yklua are lower-cased}. yk is a meta-tracing
system and yklua is yk-enabled lua
interpreter. First, I started with a recursive based approach to find 
pass sequence which doesn't violate constraints (where constraint is passing
all of yk tests and building lua interpreter to run it's tests successfully.)
Later, in the report I moved to using genetic algorithm due to it's nature
to escape local optima very efficiently. \iti{add citation} In this report
I also address the modifications I had to make to make our oracle suitable
for the genetic algorithm. 

The main contributions of this reports are: a) a parallelised genetic algorithm
for yk and yk-based interpreter b) optimised yk and yklua by 1.5x-2x times 
from baseline (where baseline was pipeline with non O2 passes) c) identified
blockers from yk which were limiting further performance optimisations with 
the help of the genetic algorithm.

The remainder of the report is organised as follows:
the next section (2) explains the background, section (3) explains methodology
(4) explains optimisation pipelines (5) covers experimental results from method
proposed. Finally, section (6) shows related work and section (7) highlights
conclusion and future work.

\section{Background}
\label{sec:background}

Constraint Satisfaction Problems are mathematical problem with a finite set of
variable, each of which has a finite domain (i.e~set of possible values).
Since the variables can be related, this puts a limitation on what values
these variables can be instantiated with. To solve this problem, we have to find
possible values for these variables which lies within the domain and does
not violates any constraints.

In this report, we would be discussing about Constraint Satisfaction
Optimisation Problem (CSOP), which is a NP-hard problem\ref{add reference}. CSOP
is a variation of Constraint Satisfaction Problem which aims to find most
optimal solution (i.e~global optima) in the search space. One way to solve this
problem is systematic search algorithm, in this method we try all possible
combinations of variables for the oracle set, the variables can have any value
possible from their domains, the algorithm then exhausts the search space (if
necessary) to find a combination which satisfies our constraint set for the
oracle(s). The problem with this search is that since the number of combination
can be exponentially large, even though it might be finite to make sure the
solution found is optimal or near-optimal the algorithm will need to exhaust the
entire problem (or search) space, this might  take years.

Another way to solve CSOP is using stochastic search method, stochastic
search method involves randomising the search algorithm. Sometimes search
based problems contains multiple local optima, and deterministic or systematic
algorithm can get stuck in local optima because of combinatorial explosion
problem. 

The objective of this report is to solve constraint optimisation problem
for YK and YKLUA using stochastic search algorithm.

\begin{itemize}
    \item 
\end{itemize}

\subsection*{Methodology}
CSOP \laurie{?}
A finite (i.e~with a countable combination) constraint satisfaction problem can
be explained as a problem with a finite set of variable, in which each variable
can have values from the domain set (which is possible values or state for that
variable). Since variables can be related to each other, these variables can 
only be instantiated with those values from their domain which doesn't violate
any constraint from the constraint set.

For easier understanding, CSOP has three variable: $X$, $D$ and $C$:
\begin{itemize}
    \item $X$ is a set of variables, ${X_1, X_2, X_3, ..., X_n}$ 
    \item $D$ is a set of domain for each variable, ${D_1, D_2, ..., D_n}$
    \item $C$ is a set of constraints that dictates allowable combinations.
\end{itemize}


backtracking or heuristic search
local search
genetic algorithm

\subsection{The LLVM Project}
As Wikipedia describes, LLVM is a set of compiler and toolchain technologies.
LLVM very modular and reusable project which has its owns Intermediate
Representation (LLVM IR). This language-independent IR helps LLVM 
compilation to be target and source independent. The LLVM IR is
optimised through sequence of LLVM passes. Passes are operational
unit of the IR which can:
    \begin{itemize}
        \item{mutate the IR}
        \item{performs some computation about the IR}
        \item{or just print something}
    \end{itemize}

A unit of an IR is scope of the pass, it's what the pass is going 
to operate on. This can be :
\begin{itemize}
    \item{a module: LLVM module is a top-level structure that represents a
        single  unit of code which is processed together. It includes global
        variable, function declaration, and implementations.}
    \item{a function: LLVM function is a self-contained unit of execution within
          a module, it corresponds to function in the source code and contains
          a list of aruguments, a basic block, and a symbol table.}
    \item{a basic block: LLVM basic block is a linear sequence of instructions
          within a function, this has a single entry and exit point. They are
          used to represent straight-line code sequence that makes up function's
          body.}
    \item{an instruction: an LLVM instruction is the smallest unit of execution
         in the LLVM IR, representing a single operation within a basic block.
         Instructions can perform a wide range of operations, including arithmetic,
         memory access, logical operations, and control flow changes. Each instruction
         produces a result and can have zero or more operands, which are either constants
         or the results of other instructions.}
\end{itemize}
These passes are categorised into analysis, transformation and utility passes.
Depending on whether they perform computation on the IR, mutate the IR,
or do some other non-categorised task.

\subsection{LLVM's optimisation pipeline}
Classically, compilers are split into three parts, which is:
frontend, middle-end and the back end. The front end is responsible
for dealing with programming-language specific analysis, this can be
operations such as parsing, type checking and so. The middle-end is where
optimisations are performed. These optimisations are target independent \iti{add
how}. Next, the backend is responsible for applying target-specific optimisation
and emiting the machine code.

Different languages like C, C++, and Rust (and many more) have their own
frontends but rely on LLVM for middle and backends.

\subsubsection{Type of optimisation pipelines}
For this report we are mostly concerned with LLVM's middle-end optimisation
pipeline. LLVM has three kind of optimisation pipeline: default (non-LTO),
ThinLTO, and FatLTO pipeline.

\subsubsection{Default Pipeline}
\subsubsection{ThinLTO Pipeline}
QUESTION: what is prelink and postlink? does every optimisation level have
prelink and postlink? (answer yes, O2/O3 is made up of prelink and postlink
union flags)

\subsubsection{FatLTO Pipeline}
\iti  {stages diagram : https://www.npopov.com/2023/04/07/LLVM-middle-end-pipeline.html}.

Question: how does passes look? (from pass slides)
Question: how to fetch prelink and postlink passes for particular level?
example using opt
Yk

Ykllvm

Yklua

\subsection*{Optimisation passes sequence}
As we discussed types of pipeline, the next question is how and what passes are
decided to be sent in prelink and postlink time? how do we know what works 
for C++ and rust? (https://www.npopov.com/2023/04/07/LLVM-middle-end-pipeline.html)

Why phase-ordering is important? Why can't we just schedule extra pass runs? 
Question: why splitting the argument was important?
Question:

Add a section about oracle, describe the oracle.

Question: why can't we use custom pipeline on our oracle?
why yk or yklua oracle tests fail for some pass sequence?

\section{Experimental Setup}

\section{Experiments}

Hypothesis I: Maintaining the order of passes are not important for finding
successful pass sequence.

Parallising the program

write about binary split algorithm

Hypothesis II: Introducing randomisation can help us escape local optima (from the GA
thesis)

parallesing the algorithm for speed-up and faster testing. 
Speed up from parallesing

Hypothesis III: Deciding upon oracle

Hypothesis IV: aiming for performance

obstacles: aiming for correctness (yk's tests), why we disabled some tests

Obstacles: wall created by ykllvm and yk-config

Hypothesis V: ykllvm's clang is slower than llvm clang because ykllvm introduce
high penality passes.

why these passes are high penality?

is there any way to solve it?

exaplain yk-config in methodology section \iti{IMPORTANT!}

 % Dynamic languages are more expensive to compile than statically
 % typed languages. Since, traditional compilers don't have runtime
 % informations, they need to emit code that can handle 
 % all type of combinations that are possible at the runtime. This
 % makes performance of dynamic language much slower. JIT compilers
 % overcome this problem by recording and using runtime informations 
 % to optimise most executed paths. JIT compilation is 
 % combination of two traditional method : ahead of time compilation
 % (AOT) and interpretation. So,

% \bibliographystyle{plain}
% \bibliography{bib}

\end{document}
