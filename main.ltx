% Main Document
\input{preamble.ltx}

\begin{document}

\maketitle

\section{Introduction}
LLVM-BOLT is a post-link static binary optimizer that enhances code layout utilizing sample-based profiling data at the binary level.
This study investigates whether providing more accurate data can improve LLVM-BOLT's performance in optimizing binaries. We conduct experiments
on building and optimizing Clang binaries using LLVM-BOLT with two data sources: perf-captured sample data and Intel-PT captured data. The analysis
aims to determine if supplying finer-grained and more branching information to
LLVM-BOLT results in further optimization of Clang binaries.

\section{Background}
Modern compilers have integrated a lot of compiler optimization techniques, such as using basic block frequencies and branch target information to perform function inlining.
But they don’t have the capability of identifying hot or cold blocks of code which can help in function splitting to improve code locality or optimize instruction cache, fortunately
this can be achieved using feedback-driven (FDO), or profile-guided optimizations (PGO). Traditional methods such as using instrumentation-based profilers have significant memory and
performance costs for collecting profiles, and they might not be able to capture accurate profiling information. With FDO, we use unmodified binaries to capture profiling data and
have only the overhead of collecting the data with much finer and accurate information. It is also easily adoptable in production environments, as one can do continuous optimization
by regularly feeding dynamic profiling data to rebuild the binary. Facebook’s BOLT (which was moved to llvm-project) uses sampled profile using perf (with and without LBR) to perform
post-link FDO on binaries.

{\fontsize{11}{13}\selectfont\textbf{2.1 Profiling Techniques}}
\newline {\fontsize{10}{12}\selectfont\textbf{Perf}}
\newline Perf, also known as perf\_event, is a lightweight Linux-based tool that offers an abstraction over hardware-specific capabilities, primarily for performance measurements.
Commonly referred to as Performance Counters for Linux, it provides per-task, per-CPU, and per-workload counters, along with the ability to sample on top of these.
Perf has four type of measurable events. Such as from pure kernel counters, in this case they are called \textbf{software events}. Examples include: context-switches, minor-faults.
\newline Another source of events is the processor itself and its Performance Monitoring Unit (PMU). It provides a list of events to measure micro-architectural events such as the number of cycles, instructions retired, L1 cache misses and so on. Those events are called \textbf{PMU hardware events} or
hardware events. They vary with each processor type and model.
\newline In \textbf{hardware cache events}, each processor gets mapped onto an actual events provided by the CPU, if they exists, otherwise the event cannot be used.
\newline And \textbf{tracepoint events} which are implemented by the kernel ftrace infrastructure.

The perf tool is in the linux-tools-common package and can also build from the Linux kernel source.
perf or perf\_events can instrument in following ways:
\begin{itemize}
	\item \textbf{counting} events in-kernel context. In counting modes, the occurrences of events are simply aggregated and presented on standard output at the end of an application run. This mode does not generate a perf.data file. We can use perf stat to generate statistics.
	\item \textbf{sampling} events write event data to a kernel buffer, which is asynchronously read by the perf to write in perf.data file. Sampling periods are based on event occurrences and not timer ticks. perf\_event emulates 64-bit counter. And every time counter overflows (i.e wraps $2^64$ to $0$) a sample is recorded, including instruction pointer when the program was interrupted.
\end{itemize}
The generated file can be read by report and script commands.

In Sampling mode with perf record , care needs to be taken about the overheads, as the capture files can quickly become
hundreds of megabytes. It depends on the rate of the event you are tracing: the more frequent, the higher the overhead and larger the perf.data size.

Another way to instrument is by using BPF program on events which can execute custom user-defined programs in kernel space, and perform filters and summaries of the data. But we won’t be covering that in our experiments.

By default perf records sample at \textbf{both} user and kernel levels using cycles events with average rate of $1000$ samples/sec or $4000$ events / sec of thread execution.  With Sampling `perf record` asks PMU to count some events, for example cpu-cycles and generate an overflow interrupt after every $n$th event (e.g a million). On every interrupt perf\_event records such as : PID/TID (Process/Thread ID), timestamp, command being executed, Instruction Pointer to the ring buffer and reset the counter to a new value.

There is a limit to maximum frequency that can be set but we can adjust both frequency of collection samples and period i.e collecting sample every Nth occurance of an event by passing -F and -c flag respectively to perf record. Once the ring buffer is filled, perf will dump the data to `perf.data` file which can be of several megabyte in size.
\newline {\fontsize{10}{12}\selectfont\textbf{LBR}}
\newline Intel’s Last Branch Record (LBR) are hardware registers used to records information about branch instructions that a CPU takes, it logs “From” and “To” addresses of each branch along with some additional metadata. The register has a ring buffer with most recent branch information, and is usually have stack depth of 8, 16, or 32 frames. 
\newline {\fontsize{10}{12}\selectfont\textbf{Intel-PT}}
\newline Intel-PT is a hardware based tracing technique integrated into CPU hardware, generating data for every control flow instruction which can be later used to resconstruct the whole control flow of a program. The frequency of capturing data is same as number of calls, branches and returns executed per second by the program. This means that per CPU, Intel-PT can capture hundreds of megabytes of trace data. 
\newline {\fontsize{8}{10}\selectfont\textbf{Buffer Handling:}}

In Intel-PT mode, perf\_events saves log to different ring buffer and perf’s user space tool will periodically save data from ring buffer for offline parsing, filtering and decoding. 

The default rate is set at 4MiB/page size for privileged user and 128KiB/page size for unprivileged users. Passing the larger buffer size is possible, but it means that multiple buffers will be logically concatenated. To switch between these buffers, an interrupt is made; sometimes these interrupts are not made in time and buffer overflows which results in trace data lost. Sometimes passing larger auxtrace mmap size helps in resolving the trace data loss, which can be done by passing `-m` flag.So, passing `-m, 64M` means we can set trace buffer size to 64MiB . However, buffer size is set per CPU and we need to be careful with choosing auxtrace mmap size. So if we have 8 CPUs we are essentially setting total 512MiB of trace buffer size. 

Another method which sometimes seems to be helpful in addition of setting AUX mmap size is re-running the workload to resolve overflow packets error. This will capture slightly less data(a couple of MiB) but you will either see no or fewer “Instruction errors” in captured data.
\newline {\fontsize{10}{12}\selectfont\textbf{Background on Bolt}}
\\
LLVM-BOLT is a static post link binary optimizer built on top of LLVM compiler infrastructure. It uses sample based profiling data to reorder function blocks.

BOLT requires profiles to be collected with relocation mode (by passing `—emit-relocs` flags) this helps BOLT to reorder basic blocks and split hot/cold blocks for improving code locality. Function discovery is initial step in order to modify the binaries. BOLT relies on ELF symbol table and function frame information (which contains functions boundaries) for function discovery.

BOLT relies on using sample based profiling methods(i.e `perf` ) to get data, the major advantage of sample based method in comparision to instrumentation one is better (or more accurate) information with minimal operational complexity. 

{\fontsize{8}{10}\selectfont\textbf{Optimizing Clang with Bolt}}

We decided to replicate optimizing Clang binary with LLVM-BOLT. For this experiment we built  of Clang( version 16.0.3) and later bootstrapped it with PGO and LTO. (Add a line about PGO and LTO?). Finally, we use the bootstraped version to collect profile for a new clang build in : No LBR, LBR and PT mode.

In LBR mode, LLVM-BOLT uses perf to fetch PID/TID, Instruction Pointer (IP) and Branch Stack (brstack). LLVM-BOLT expects branch flags to either predict or mispredict, but branch flags are not supported by Intel PT. 

To make LLVM-BOLT work we need to add configuration option in perfconfig file which sets mispred flag on all branches. Simply adding following lines to \~/.perfconfig should let us get brstack information out of sampled data collected with PT

\begin{lstlisting}[language=bash]

[intel-pt]

mispred-all = on

\end{lstlisting}

We will need to modify the data aggregation code in LLVM-BOLT to utilize the -itrace=i100usle option in conjunction with the perf script, which extracts the brstack field from the data gathered through Intel PT.

[Add script to replicate the experiment?]

We will be using multitime to time the benchmark runs on compilation of gcc.c with baseline and optimized Clang builds.

\begin{table}[ht]
\centering
\caption{Benchmarking of clang versions on gcc.c}
\begin{tabular}{l|rrrrr}
\hline
\textbf{Category} & \textbf{Mean} & \textbf{Std.Dev.} & \textbf{Min} & \textbf{Median} & \textbf{Max} \\ \hline
Baseline clang & 8.938 & 0.187 & 8.771 & 8.843 & 9.199 \\
(user) & 8.375 & 0.071 & 8.276 & 8.422 & 8.429 \\
(sys) & 0.448 & 0.030 & 0.410 & 0.452 & 0.482 \\ \hline
NoLBR & 6.790 & 0.039 & 6.735 & 6.810 & 6.824 \\
(user) & 6.369 & 0.045 & 6.306 & 6.390 & 6.412 \\
(sys) & 0.405 & 0.016 & 0.382 & 0.416 & 0.417 \\ \hline
LBR & 6.764 & 0.005 & 6.757 & 6.767 & 6.768 \\
(user) & 6.338 & 0.013 & 6.326 & 6.332 & 6.356 \\
(sys) & 0.412 & 0.018 & 0.388 & 0.420 & 0.429 \\ \hline
Intel PT & 6.649 & 0.070 & 6.550 & 6.692 & 6.704 \\
(user) & 6.184 & 0.032 & 6.144 & 6.186 & 6.222 \\
(sys) & 0.454 & 0.041 & 0.404 & 0.454 & 0.505 \\ \hline
\end{tabular}
\label{table:benchmark_analysis}
\end{table}

\textbf{Performance comparision:}

Number of functions bolt reorders (\% of profiled data \& \% of total number of functions)
\begin{table}[ht]
\centering
\caption{Analysis of function reordering by LLVM BOLT in different modes}
\begin{tabular}{l|rrr}
\hline
\textbf{Profiled Functions} & \textbf{Function reordered} & \textbf{wrt profiled functions} & \textbf{wrt total functions} \\ \hline
No LBR & 311 & 73.95\% & 0.13\% \\
LBR & 1501 & 71.95\% & 0.62\% \\
Intel PT & 4177 & 69.43\% & 1.65\% \\ \hline
\end{tabular}
\label{table:function_reordering}
\end{table}

\textbf{Analysis of number of function executed during compilation, number of function perf shows in sampling mode and number of functions Bolt reorders}
Out of 175120 functions in Clang binary, LLVM-BOLT seems to reorder 230 functions in NO LBR mode, 1080 functions in LBR mode and 2900 functions in Intel PT mode. What’s interesting is the more profiling data we capture LLVM BOLT reorders more functions but the performance improvement seems is not too much. 

So, the NO LBR, LBR, and Intel PT  binaries are approximately 31.6\%, 32.1\%, and 34.4\% faster than the baseline binary, respectively. There is not too much improvement by feeding more profiling information with Intel PT.

To understand the reason, we can observe the number of functions of Clang being executed during compilation of extsmaild.c file (the test file we are using to collect profiling information).

We will be using two tools, Callgrind, a profiling tool included in Valgrind suite and llvm-cov to get the numbers of executed functions. 

Callgrind tracks the callgraph (in simple terms function call hierarchy) of a program during its execution. It dumps information about number of times each function is called, number of instructions being executed and number of cycles consumed by each functions in a callgrind.out.PID file. We are only interested in number of functions being executed. To easily study the dumped data, we will be using QCachegrind (MacOS version KCachegrind).

llvm-cov is part of LLVM project used for generating code coverage information for C/C++ and other LLVM supported languages(including but not limited to function coverage, which is more important for us). 

[Difference between llvm-cov and Valgrind]

Valgrind shows us that around x\% of functions are executed during Compilation and llvm-cov shows it to be around y\%.

[Add image]

We could only capture around 3874 i.e 15\% of executed functions with perf. But noticing at the performance improvement we can make a guess that captured profiles by perf which contibute most to BOLT for binary optimization. This mean, feeding BOLT more accurate data captured with Intel PT wouldn’t give any meaningful optimization. 

(At runtime the counters are incremented and at exit the counters are dumped in gcda files. source: [https://clang.llvm.org/docs/UsersManual.html](https://clang.llvm.org/docs/UsersManual.html))
\end{document}
